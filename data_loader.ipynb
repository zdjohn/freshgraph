{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: HetRec 2011 MovieLens + IMDb/Rotten Tomatoes\n",
    "https://grouplens.org/datasets/hetrec-2011/\n",
    "readme: http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from freshgraph import data_loader\n",
    "from freshgraph.data_loader import user_item_tuple_train, movie_meta, movies_validate, movie_genres, movie_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data into graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "movie_feature_graph = data_loader.get_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: candidating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "## tensorflow warning supression\n",
    "from freshgraph import candidating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create metapath2vec based model for item to item similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: training similarity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# training will take about 20+- mins, once trained this step can be skipped\n",
    "metapath2vec_model = candidating.train_candidates_model(movie_feature_graph)\n",
    "metapath2vec_model.save(\"movie.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### step 1: load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 38.7 ms, total: 284 ms\n",
      "Wall time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import Word2Vec\n",
    "metapath2vec_model = Word2Vec.load(\"movie.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_validate[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Star Trek IV: The Voyage Home']\n",
      "0.5979886651039124\n",
      "['Star Trek III: The Search for Spock']\n",
      "0.5717388987541199\n",
      "['Star Trek V: The Final Frontier']\n",
      "0.5665578842163086\n",
      "['Mission: Impossible III']\n",
      "0.5640816688537598\n",
      "['Titanica']\n",
      "0.5558382272720337\n",
      "['Star Trek: The Wrath of Khan']\n",
      "0.5479453206062317\n",
      "['Star Trek VI: The Undiscovered Country']\n",
      "0.5397538542747498\n",
      "['Mission: Impossible III']\n",
      "0.5361419916152954\n",
      "['Destiny in Space']\n",
      "0.5297540426254272\n",
      "['Bottle Shock']\n",
      "0.5221686363220215\n"
     ]
    }
   ],
   "source": [
    "validate_id = 3884 #, Star Trek, 25940\tThe Lady from Shanghai\t\n",
    "\n",
    "similar_items = candidating.get_similar_items(metapath2vec_model, validate_id)\n",
    "ordered_item_list = candidating.sort_similar_item_by_score(similar_items)\n",
    "for x in ordered_item_list[:10]:\n",
    "    print(movie_meta[movie_meta['id'] == int(x[0])]['title'].values)\n",
    "    print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_users = candidating.get_ranked_candidates(user_item_tuple_train, similar_items)\n",
    "candidate_ids = [x[0] for x in ranked_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID\n",
       "1      75       32\n",
       "2      75      110\n",
       "4      75      163\n",
       "5      75      165\n",
       "6      75      173"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_tuple_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: drift detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create user-items and item-users mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 24.1 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "# user-items tuples based on candidate\n",
    "candidate_items_tuple = user_item_tuple_train[user_item_tuple_train['userID'].isin([int(x) for x in candidate_ids])]\n",
    "\n",
    "# user-items tuples based on all positive pairs\n",
    "# candidate_items_tuple = user_item_tuple_train\n",
    "\n",
    "user_items_dict = defaultdict(list)\n",
    "candidate_items_subgraph = [user_items_dict[x['userID']].append(x['movieID']) for _, x in candidate_items_tuple.iterrows()]\n",
    "\n",
    "item_users_dict = defaultdict(list)\n",
    "item_candidates_subgraph = [item_users_dict[x['movieID']].append(x['userID']) for _, x in candidate_items_tuple.iterrows()]\n",
    "\n",
    "\n",
    "def partition_vertices(user_id, partition_user_dict, partition_item_dict, partition_index):\n",
    "    partition_user_dict[user_id] = partition_index\n",
    "    grouped_candidate_list = []\n",
    "    for item_id in user_items_dict[user_id]:\n",
    "        if item_id not in partition_item_dict:\n",
    "            partition_item_dict[item_id]=partition_index\n",
    "            grouped_candidate_list += item_users_dict[item_id]\n",
    "#     print(grouped_candidate_list)\n",
    "    for related_user_id in set(grouped_candidate_list):\n",
    "        if related_user_id not in partition_user_dict:\n",
    "            partition_vertices(related_user_id, partition_user_dict, partition_item_dict, partition_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067\n",
      "9096\n"
     ]
    }
   ],
   "source": [
    "print(len(user_items_dict))\n",
    "print(len(item_users_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create partition on user and item nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "partition_user_dict={}\n",
    "partition_item_dict={}\n",
    "partition_count = 0\n",
    "\n",
    "    \n",
    "for user_id in candidate_ids:\n",
    "    if user_id not in partition_user_dict:\n",
    "        partition_vertices(user_id, partition_user_dict, partition_item_dict, partition_count)\n",
    "        partition_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freshgraph",
   "language": "python",
   "name": "freshgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
